# ðŸ§ª Jigsaw Toxic Comment Classification

This project is based on the Jigsaw Toxic Comment Classification Challenge. The goal is to build a multi-label classifier that identifies toxic behavior in online comments.

---

## ðŸ“Œ What I Did

- Explored and visualized class imbalance in toxic labels
- Preprocessed the text (lowercasing, punctuation removal, tokenization)
- Used an Embedding + Bidirectional GRU-based RNN model for multi-label classification
- Trained and validated the model using F1-score as metric
- Prepared submission and tested on Kaggle

---

## ðŸ§  Model Highlights

- Tokenizer + padded sequences
- Embedding layer using pre-trained GloVe vectors
- BiGRU layers with dropout
- Sigmoid activation for multilabel outputs

---

## ðŸ“Š Evaluation

| Method | Public Score | Private Score |
|--------|--------------|---------------|
| Deep Learning (RNN + GRU) | **0.94183** | **0.94440** |

---

## ðŸ“‚ Structure
jigsaw-toxic-comment-classification/
â”œâ”€â”€ jigsaw_nlp_rnn_live.ipynb
â””â”€â”€ README.md

---

## âœ… What I Learned

- How to build multi-label text classifiers
- How to use pre-trained embeddings for better results
- The importance of handling class imbalance in toxic comment datasets
- How to optimize a Kaggle submission

---

ðŸ“š *Project by Simi â€” 2nd Year B.Tech, MNNIT*

